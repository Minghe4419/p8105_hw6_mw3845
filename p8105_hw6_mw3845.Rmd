---
title: "p8105_hw6_mw3845"
author: "Minghe Wang"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(purrr)
library(tidyr)
library(modelr)
```

# Problem 1

# Problem 2

```{r Problem2_clean_data}
homicide_df = read.csv("./data/homicide-data.csv")

homicide_df <- homicide_df %>% 
  mutate(
    city_state = paste(city, state, sep = ", "),
    solved_case = case_when(
      disposition %in% c("Closed without arrest", "Open/No arrest") ~ 0,
      disposition == "Closed by arrest" ~ 1
    )
  ) %>% 
  filter(
    !(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")) &
    victim_race %in% c("White", "Black")
  ) %>% 
  mutate(
    victim_age = ifelse(victim_age == "Unknown", NA, victim_age),
    victim_age = as.numeric(as.character(victim_age))
  )
```

After loading and cleaning data, the dataset `homicide_df` contains `r nrow(homicide_df)` rows and `r ncol(homicide_df)` columns. Key variables includes `victim_age`, `victim_race`, `city_state`, `solved_case`, etc. The variables will be used for model fitting for each city.

```{r Problem2_baltimore_result}
baltimore_df = homicide_df %>% 
  filter(city_state == "Baltimore, MD") %>% 
  select(solved_case, victim_age, victim_race, victim_sex)

baltimore_glm = 
  baltimore_df |> 
  glm(solved_case ~ victim_age + victim_race + victim_sex, data = _, family = binomial())

baltimore_result = baltimore_glm |> 
  broom::tidy(
    exponentiate = TRUE,
    conf.int = TRUE
  ) |> 
  filter(term == "victim_sexMale") |>
  select(term, estimate, conf.low, conf.high, p.value)

baltimore_result |> 
  knitr::kable(digits = 4)
```

We select `Baltimore, MD`'s data and fit into binary logistic regression model with `glm`. We use variables `victim_age`, `victim_race`, `victim_sex` to make prediction on `solved_case`. By comparing victims' sex, we obtain estimated odd ratio for solving homicide `r pull(baltimore_result, estimate)` and 1 does not falls into the 95% confidence interval. It indicate that cases committed by male victims have less odd to be solved than cases committed by female; and the result is statistically significant.

```{r Problem3_glm_thru_cities}
city_model = homicide_df %>% 
  group_by(city_state) %>% 
  nest() %>% 
  mutate(
    glm_model = map(
      data,
      ~ glm(solved_case ~ victim_age + victim_race + victim_sex, data = ., family = binomial())
    )
  ) 

city_result = city_model %>% 
  mutate(
    tidy_glm_model = map(glm_model, broom::tidy)
  ) %>% 
  unnest(tidy_glm_model) %>% 
  mutate(
    OR = exp(estimate),
    ci_lower = exp(estimate - 1.96 * std.error),
    ci_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  filter(term == "victim_sexMale") %>%
  select(
    city_state,
    OR,
    ci_lower,
    ci_upper,
    p.value
  )

city_result %>% 
  knitr::kable(digits = 4)

city_result = city_result %>%
  arrange(OR) %>%
  mutate(city_state = factor(city_state, levels = city_state))

ggplot(city_result, aes(x = OR, y = city_state)) +
  geom_point() +
  geom_errorbar(aes(xmin =  ci_lower, xmax =  ci_upper), width = 0.2) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
  xlab("Adjusted Odds Ratio (Male vs Female Victims)") +
  ylab("City, State") +
  ggtitle("Adjusted Odds Ratios for Solving Homicides by City") +
  theme_minimal()
```

For the adjusted odd ratio plot, we observe that the male victim committed homicide are less likely to be solved than female committed homicides in most cities. We need to be careful for the cities with estimated confidence interval including 1 because it typically suggest that the result is not statistically significant at the 95% confidence level.

# Problem 3

```{r Problem3_data_cleaning}
bwt_df = 
  read_csv("./data/birthweight.csv") |> 
  janitor::clean_names() |>
  mutate(
    babysex = 
        case_match(babysex,
            1 ~ "male",
            2 ~ "female"
        ),
    babysex = fct_infreq(babysex),
    frace = 
        case_match(frace,
            1 ~ "white",
            2 ~ "black", 
            3 ~ "asian", 
            4 ~ "puerto rican", 
            8 ~ "other"),
    frace = fct_infreq(frace),
    mrace = 
        case_match(mrace,
            1 ~ "white",
            2 ~ "black", 
            3 ~ "asian", 
            4 ~ "puerto rican",
            8 ~ "other"),
    mrace = fct_infreq(mrace),
    malform = as.logical(malform))

sapply(bwt_df, function(x) sum(is.na(x)))

```

After importing and cleaning the birth weight data, there are `r nrow(bwt_df)` rows and `r ncol(bwt_df)` columns. We factored `babysex`, `frace`, `mrace`, `malform` in the dataset. The dataset also includes key variables like `blength`, `gaweeks`, `bhead`, etc; which are important for out future model fitting and comparison process. By checking for NA, we found there is no missing value in our cleaned dataset.

```{r Problem3_hypothesized_model}
hypothesis_model <- lm(bwt ~ gaweeks + babysex + ppbmi + smoken + mrace + wtgain, data = bwt_df)
summary(hypothesis_model)

bwt_df <- bwt_df %>%
  add_predictions(hypothesis_model) %>%
  add_residuals(hypothesis_model)

# Plot Residuals vs. Fitted Values
ggplot(bwt_df, aes(x = pred, y = resid)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Residuals vs. Fitted Values",
       x = "Fitted Values (Predicted Birthweight)",
       y = "Residuals") +
  theme_minimal()
```

In the hypothesized model that we construct, the baby's measurement at birth and the mother's health information (`gaweeks`, `babysex`, `ppbmi`, `smoken`, `mrace`, `wtgain`) are included to predict the birth weight `bwt`. All variables are considered statistically significant according to the summary table.

From the scatter plot of Residual vs. Prediction, we observe no specific pattern of how residuals are distributed, which can be considered as randomly dispersed around then 0 line. Thus we conclude that this it a goot fit that the model appropriately captures the relationship between predictors and the outcome.

```{r Problem3_model_comparison}
cv_df = 
  crossv_mc(bwt_df, 100)

cv_df = 
  cv_df |> 
  mutate(
    hypothesis_mod  = map(train, \(df) lm(bwt ~ gaweeks + babysex + ppbmi + smoken + mrace + wtgain, data = df)),
    main_effect_mod  = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    interaction_mod  = map(train, \(df) lm(bwt ~ (bhead + blength + babysex)^3, data = df))
  ) |> 
  mutate(
    rmse_hypothesis = map2_dbl(hypothesis_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_main_effect = map2_dbl(main_effect_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_interact = map2_dbl(interaction_mod, test, \(mod, df) rmse(model = mod, data = df)))


cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

The 3-way interaction model outperforms the other 2 models. This is align with our tuition because the 3-way interaction model can capture non-linear / complex relationships when making prediction on babies' birth weight. The main effect model outperform our initial hypothesized model might indicate that out hypothesized model containing more variables than the main effect model does might introduce noises to the relationship. While the `gaweeks` and `blength` are likely to be strong predicting variables, it is reasonable that the hypothesized model has highest prediction error in comparison.

